{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/soniamannan/Documents/DATA401/capstone/DigitalDemocracyCapstone/data/\"\n",
    "target_col = 'transition_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_output_filename = data_dir + \"training/training_utterances_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_output_binary_filename = data_dir + \"training/training_utterances_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset evenly based on labels\n",
    "def split_test_train(total, stratify_col):\n",
    "    transition_rows = total[total[stratify_col] != 0]\n",
    "    non_transition_rows = total[total[stratify_col] == 0]\n",
    "    \n",
    "    # first split transitions into training/testing\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(transition_rows, \n",
    "                                                    transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # assert there are only transition labels in this dataframe\n",
    "    assert len(X_train1[X_train1[target_col] == 0]) == 0\n",
    "    assert len(X_test1[X_test1[target_col] == 0]) == 0\n",
    "    \n",
    "    train_len = len(X_train1) # number of non-transitions to add to training set\n",
    "    test_len = len(X_test1) # number of non-transitions to add to testing set\n",
    "    \n",
    "    \n",
    "    # next split non-transitions into training/testing\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(non_transition_rows, \n",
    "                                                    non_transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # pick train_len random rows from non-transition training set\n",
    "    X_train2 = X_train2.sample(n = train_len, axis=0)\n",
    "    \n",
    "    # pick test_len random rows from non_transitions testing set\n",
    "    X_test2 = X_test2.sample(n = test_len, axis=0)\n",
    "    \n",
    "    # assert there are no transition utterances in non-transition training and testing set\n",
    "    assert len(X_train2[X_train2[target_col] != 0]) == 0\n",
    "    assert len(X_test2[X_test2[target_col] != 0]) == 0\n",
    "    \n",
    "    # final result, concat the dataframe\n",
    "    X_train_final = pd.concat([X_train1, X_train2])\n",
    "    X_test_final = pd.concat([X_test1, X_test2])\n",
    "    \n",
    "    return X_train_final['text'], X_test_final['text'], X_train_final[target_col], X_test_final[target_col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assert training/testing split is balanced\n",
    "def verify_train_test_split(train, x_train, y_train, x_test, y_test):\n",
    "    transition_rows = train[train[target_col] != 0]\n",
    "    assert len(x_train) == len(y_train)\n",
    "    assert len(x_test) == len(y_test)\n",
    "    assert len(x_train) == int(len(transition_rows) * 0.7) * 2\n",
    "    assert len(x_test) == (len(transition_rows) * 2) - (int(len(transition_rows) * 0.7) * 2)\n",
    "    assert len(y_train[y_train == 0]) == len(y_train[y_train != 0])\n",
    "    assert len(y_test[y_test == 0]) == len(y_test[y_test != 0])\n",
    "    print (\"{0}% of utterances are transitions\".format((sum(y_train) / len(x_train)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract bag of words features from text for a model\n",
    "def bag_of_words_features(x_train, x_test):\n",
    "    count_vect = CountVectorizer()\n",
    "    count_vect.fit(np.hstack((x_train)))\n",
    "    X_train_counts = count_vect.transform(x_train)\n",
    "    X_test_counts = count_vect.transform(x_test)\n",
    "    \n",
    "    assert X_train_counts.shape[1] == X_test_counts.shape[1]\n",
    "    \n",
    "    return X_train_counts, X_test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output accuracy for a naive bayes model\n",
    "# return the trained model\n",
    "def model(X_train_counts, X_test_counts, y_train, y_test):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_counts, y_train)\n",
    "    \n",
    "    assert X_test_counts.shape[0] == y_test.shape[0]\n",
    "    \n",
    "    acc = clf.score(X_test_counts, y_test, sample_weight=None)\n",
    "    print(\"Model accuracy {0}\".format(acc))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_transcript(train, n):\n",
    "    total = len(np.unique(train['video_id']))\n",
    "    ids = np.unique(train['video_id'])[:n]\n",
    "    rows = train[train['video_id'].isin(ids)]\n",
    "    train = train[~(train['video_id'].isin(ids))]\n",
    "    \n",
    "    assert len(np.unique(rows['video_id'])) == n\n",
    "    assert len(np.unique(train['video_id'])) == total - n\n",
    "    \n",
    "    return train, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the prefix POST to all utterances n after\n",
    "# adds the prefix PRE to all utterances n before\n",
    "# a transition phrase\n",
    "def add_context(n):\n",
    "    n_range = pd.read_csv(training_output_binary_filename, sep=\"~\")\n",
    "    \n",
    "    transition_text = n_range['text']\n",
    "    labels = n_range['transition_value']\n",
    "    \n",
    "    new_transition_labels = []\n",
    "    new_transition_text = []\n",
    "\n",
    "    length = len(n_range)\n",
    "    \n",
    "    for i in range(length):\n",
    "        # get the phrases in the window\n",
    "        text = ''\n",
    "        for x in range(-n, n+1):\n",
    "            # window is within range of the dataframe\n",
    "            if (i + x >= 0 and i + x < length):\n",
    "                if (x > 0):\n",
    "                    text += ' '.join([\"POST-\" + x for x in transition_text[i+x].split()])\n",
    "                if (x < 0):\n",
    "                    text += ' '.join([\"PRE-\" + x for x in transition_text[i+x].split()])\n",
    "                else:\n",
    "                    text += ' ' + transition_text[i+x] + ' '\n",
    "                    \n",
    "        new_transition_text.append(text)\n",
    "    \n",
    "    print (\"Number of new phrases {0}\".format(len(new_transition_text)))\n",
    "    print (\"Number of labels {0}\".format(len(n_range['transition_value'])))\n",
    "    \n",
    "    return pd.DataFrame({'text':new_transition_text,'transition_value':n_range['transition_value']}, \n",
    "     columns=['text', target_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_table(training_output_filename, sep=\"~\")[['text', target_col, 'video_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transitions in the dataset 2869\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of transitions in the dataset {0}\".format(len(train[train['transition_value'] != 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>transition_value</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please call the roll our anderson no</td>\n",
       "      <td>0</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nobel by very he'll know block i</td>\n",
       "      <td>0</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can my daily all bipolar no games.</td>\n",
       "      <td>0</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no, ...only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know paul.</td>\n",
       "      <td>0</td>\n",
       "      <td>4161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  transition_value  video_id\n",
       "0  please call the roll our anderson no                 0      4161\n",
       "1      nobel by very he'll know block i                 0      4161\n",
       "2    can my daily all bipolar no games.                 0      4161\n",
       "3                       no, ...only ...                 0      4161\n",
       "4                            know paul.                 0      4161"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove top 5 videos from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, transcripts = remove_transcript(train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transitions in dataset after removing top 5 transcripts 2857\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of transitions in dataset after removing top 5 transcripts {0}\"\n",
    ".format(len(train[train['transition_value'] != 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_test_train(train[['text', target_col]], target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_rows = train[train[target_col] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert training and testing splits are the correct dimensions\n",
    "### After splitting, training and testing sets should each have 50% transitions and 50% non-transitions\n",
    "### training dimensions should be 2 * 70% of the number of transitions in the data set\n",
    "### testing dimensions should be 2 * 30% of the number of transitions in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(x_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(x_train) == int(len(transition_rows) * 0.7) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(x_test) == (len(transition_rows) * 2) - (int(len(transition_rows) * 0.7) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(y_train[y_train == 0]) == len(y_train[y_train != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(y_test[y_test == 0]) == len(y_test[y_test != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% of utterances are transitions\n"
     ]
    }
   ],
   "source": [
    "print (\"{0}% of utterances are transitions\".format((sum(y_train) / len(x_train)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80328     We have a quorum, like to ask our guests and v...\n",
       "85190                 [UNKNOWN], our first hearing of 2016.\n",
       "204322                                    No. >> No, Bates?\n",
       "141781                                       Aye,Hernandez?\n",
       "126973                   Motions, resolutions, and notices.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize utterances with bag of words features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass vectorized utterances into a Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output accuracy on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.5477855477855478\n"
     ]
    }
   ],
   "source": [
    "X_train_counts, X_test_counts = bag_of_words_features(x_train, x_test)\n",
    "bag_of_words_model = model(X_train_counts, X_test_counts, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_predicted_to_actual(clf, X_test_counts, x_test, y_test, outfilename):\n",
    "    # get predicted values\n",
    "    preds = clf.predict(X_test_counts)\n",
    "    \n",
    "    print(\"% predictions that were 1's {0}\\n\".format(sum(preds) / len(preds)))\n",
    "    \n",
    "    # add predicted values to original dataframe\n",
    "    total = pd.concat([x_test, y_test], axis=1)\n",
    "    total['predicted'] = preds\n",
    "    \n",
    "    # get the incorrect predictions and write to a csv\n",
    "    wrongs = total[total['transition_value'] != total['predicted']]\n",
    "    wrongs.to_csv(outfilename)\n",
    "    \n",
    "    print (\"Example of an incorrect transition\\n\")\n",
    "    print (list(wrongs['text'])[0])\n",
    "    print (\"Actual {0}\".format(list(wrongs['transition_value'])[0]))\n",
    "    print (\"Predicted {0}\".format(list(wrongs['predicted'])[0]))\n",
    "    \n",
    "    return wrongs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at what the wrong predictions actually are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% predictions that were 1's 0.5442890442890443\n",
      "\n",
      "Example of an incorrect transition\n",
      "\n",
      "I ask for an aye vote on this resolution.\n",
      "Actual 1\n",
      "Predicted 0\n"
     ]
    }
   ],
   "source": [
    "wrongs = compare_predicted_to_actual(bag_of_words_model, X_test_counts, \n",
    " x_test, y_test, data_dir+'predictions/wrong_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize utterances with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf(x_train, x_test):\n",
    "    X_train_counts, X_test_counts = bag_of_words_features(x_train, x_test)\n",
    "    \n",
    "    transformer = TfidfTransformer(smooth_idf=True)\n",
    "    Xtrain_tfidf = transformer.fit_transform(X_train_counts)\n",
    "    Xtest_tfidf = transformer.fit_transform(X_test_counts)\n",
    "    \n",
    "    assert Xtrain_tfidf.shape[1] == Xtest_tfidf.shape[1]\n",
    "    \n",
    "    return Xtrain_tfidf, Xtest_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_tfidf, Xtest_tfidf = transform_tfidf(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.539044289044289\n"
     ]
    }
   ],
   "source": [
    "tf_idf_model = model(Xtrain_tfidf, Xtest_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Vectorize utterances with n-gram features\n",
    "### Best accuracy when combining unigram and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_ngram(start, stop, x_train, x_test):\n",
    "    ngram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(start, stop))\n",
    "    counts = ngram_vectorizer.fit(np.hstack((x_train)))\n",
    "    \n",
    "    print (\"Number of transformed features {0}\\n\"\n",
    "     .format(len(ngram_vectorizer.get_feature_names())))\n",
    "    \n",
    "    print (\"First 10 features\\n{0}\"\n",
    "     .format('\\n'.join(ngram_vectorizer.get_feature_names()[-10:])))\n",
    "    \n",
    "    X_train_counts = counts.transform(x_train)\n",
    "    X_test_counts = counts.transform(x_test)\n",
    "    \n",
    "    assert X_train_counts.shape[1] == X_test_counts.shape[1]\n",
    "    \n",
    "    return X_train_counts, X_test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformed features 26940\n",
      "\n",
      "First 10 features\n",
      "zero for\n",
      "zero measure\n",
      "zero please\n",
      "zero the\n",
      "zero there\n",
      "zero vote\n",
      "zevs\n",
      "zevs vehicle\n",
      "zone\n",
      "zone even\n"
     ]
    }
   ],
   "source": [
    "X_train_ngram_counts, X_test_ngram_counts = transform_ngram(1, 2, x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.5402097902097902\n"
     ]
    }
   ],
   "source": [
    "ngram_model = model(X_train_ngram_counts, X_test_ngram_counts, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For utterances in a transcript, tag what the model predicts the utterance to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_entire_transcript(transcripts, x_train, x_test, y_train, y_test):\n",
    "    print(\"{0}\\n\".format(transcripts.head()))\n",
    "    \n",
    "    count_vect = CountVectorizer()\n",
    "    count_vect.fit(np.hstack((x_train)))\n",
    "    transcripts_test = count_vect.transform(transcripts['text'])\n",
    "    label = transcripts['transition_value']\n",
    "    \n",
    "    X_train_counts, X_test_counts = bag_of_words_features(x_train, x_test)\n",
    "    bag_of_words_model = model(X_train_counts, X_test_counts, y_train, y_test)\n",
    "    \n",
    "    preds = bag_of_words_model.predict(transcripts_test)\n",
    "    \n",
    "    assert len(preds) == transcripts_test.shape[0]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   text  transition_value  video_id\n",
      "0  Please call the roll our anderson no                 0      4161\n",
      "1      Nobel by very he'll know block I                 0      4161\n",
      "2    can my daily all bipolar no games.                 0      4161\n",
      "3                       No, ...only ...                 0      4161\n",
      "4                            Know paul.                 0      4161\n",
      "\n",
      "Model accuracy 0.5477855477855478\n"
     ]
    }
   ],
   "source": [
    "preds = predict_entire_transcript(transcripts, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please call the roll our anderson no</td>\n",
       "      <td>4161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nobel by very he'll know block I</td>\n",
       "      <td>4161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can my daily all bipolar no games.</td>\n",
       "      <td>4161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, ...only ...</td>\n",
       "      <td>4161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Know paul.</td>\n",
       "      <td>4161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  video_id  predicted  actual\n",
       "0  Please call the roll our anderson no      4161          1       0\n",
       "1      Nobel by very he'll know block I      4161          1       0\n",
       "2    can my daily all bipolar no games.      4161          1       0\n",
       "3                       No, ...only ...      4161          0       0\n",
       "4                            Know paul.      4161          0       0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = transcripts.copy()\n",
    "res['predicted'] = preds\n",
    "res['actual'] = transcripts['transition_value']\n",
    "res = res.drop(['transition_value'], axis=1)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.to_csv('/Users/soniamannan/Documents/DATA401/capstone/DigitalDemocracyCapstone/data/predictions/binary_predicted_transcript.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a context prefix to surrounding utterances\n",
    "### Collapse the context (with prefix) and train on bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new phrases 656444\n",
      "Number of labels 656444\n"
     ]
    }
   ],
   "source": [
    "n_range = add_context(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transitions = n_range[n_range['transition_value'] != 0]\n",
    "non_transitions = n_range[n_range['transition_value'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transition phrases 2869\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of transition phrases {0}\".format(len(transitions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of utterances 631713\n"
     ]
    }
   ],
   "source": [
    "print (\"Total number of utterances {0}\".format(len(collapsed_n_range)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example transition\n",
      "\n",
      "PRE-...runner PRE-no PRE-snow.PRE-no, PRE-...act.PRE-no, PRE-why PRE-cassie PRE-i PRE-...PRE-...the PRE-apps PRE-members PRE-please PRE-now.PRE-...eyes PRE-twenty-four PRE-knows PRE-fourteen PRE-the PRE-measure PRE-passes PRE-we're PRE-going to start at the top of the file colleagues which is file item eighty eight. POST-senator POST-jackson. senator jackson. POST-file POST-out POST-of POST-eighty-eight POST-pass POST-on POST-file POST-item POST-eighty POST-nine. file out of eighty-eight pass on file item eighty nine. POST-so, POST-the POST-bill POST-three POST-thirteen POST-together POST-gianni POST-perform POST-file. so, the bill three thirteen together gianni perform file. POST-file POST-item POST-ninety POST-two POST-<BILL_ID> POST-for POST-three POST-four POST-center file item ninety two <BILL_ID> for three four center POST-allen. allen. \n"
     ]
    }
   ],
   "source": [
    "print (\"Example transition\\n\\n{0}\".format(list(transitions['text'])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example non-transitions\n",
      "\n",
      "PRE-by PRE-hancock PRE-...PRE-...i PRE-...where PRE-...hilton PRE-highway PRE-so.PRE-i PRE-half.PRE-no, PRE-jackson.PRE-lever PRE-by PRE-loop PRE-i'm PRE-acquire ...but i mean there's a time it's so high POST-...by POST-more POST-lock. ...by more lock. POST-no, POST-...you POST-know, POST-when? no, ...you know, when? POST-no, POST-nielsen POST-no POST-... no, nielsen no ... POST-i'd POST-have POST-lee. i'd have lee. POST-...runner POST-no POST-snow. ...runner no snow. \n"
     ]
    }
   ],
   "source": [
    "print (\"Example non-transitions\\n\\n{0}\".format((list(non_transitions['text'])[10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a new training/testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_context, x_test_context, \\\n",
    " y_train_context, y_test_context = split_test_train(n_range[['text', target_col]], target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% of utterances are transitions\n"
     ]
    }
   ],
   "source": [
    "verify_train_test_split(n_range, x_train_context, y_train_context, x_test_context, y_test_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.6225319396051103\n"
     ]
    }
   ],
   "source": [
    "X_train_counts, X_test_counts = bag_of_words_features(x_train_context, x_test_context)\n",
    "bag_of_words_model = model(X_train_counts, X_test_counts, y_train_context, y_test_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformed features 159334\n",
      "\n",
      "First 10 features\n",
      "zoning and\n",
      "zoning our\n",
      "zoning post\n",
      "zoning pre\n",
      "zoning standards\n",
      "zoo\n",
      "zoo as\n",
      "zoo post\n",
      "zoo pre\n",
      "zoo they\n"
     ]
    }
   ],
   "source": [
    "X_train_ngram_counts, X_test_ngram_counts = transform_ngram(1, 2, x_train_context, x_test_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.6451800232288037\n"
     ]
    }
   ],
   "source": [
    "ngram_model = model(X_train_ngram_counts, X_test_ngram_counts, y_train_context, y_test_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use WordNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace words in an utterance with their synset\n",
    "def get_synset_from_text(utterance):\n",
    "    for word in utterance.split():\n",
    "        syn = wordnet.synsets(word)\n",
    "        lemmas = set([s.lemmas()[0].name() for s in syn])\n",
    "        if syn: utterance = utterance.replace(word, ' '.join(lemmas))\n",
    "        \n",
    "    return utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with their synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_word_net = [get_synset_from_text(x) for x in x_train]\n",
    "x_test_word_net = [get_synset_from_text(x) for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alight ignite light idle easy unhorse Inner_Light abstemious lightly luminosity light_up lighter unaccented fall faint sparkle clean all_all_over over complete all_over over complete complete dark iniquity darkness and good all_all_over over complete all_over over complete complete corruption. '"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_word_net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mister electric_chair moderate chair president professorship and members, George Thompson along, on along behalf of the California aesculapian medical checkup Association along, '"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_word_net[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize synsets with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(np.hstack((x_train)))\n",
    "X_train_counts = count_vect.transform(x_train)\n",
    "X_test_counts = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_train_counts.shape[1] == X_test_counts.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_test_counts.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55986316989737739"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_counts, y_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample utterance and synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB\n",
      "{'Bachelor_of_Science', 'antimony'}\n",
      "[Synset('antimony.n.01'), Synset('bachelor_of_science.n.01')]\n",
      "1008\n",
      "set()\n",
      "[]\n",
      "would\n",
      "set()\n",
      "[]\n",
      "extend\n",
      "{'strain', 'stretch', 'gallop', 'unfold', 'run', 'cover', 'offer', 'carry', 'prolong', 'exsert', 'extend', 'widen'}\n",
      "[Synset('widen.v.04'), Synset('run.v.03'), Synset('cover.v.03'), Synset('extend.v.04'), Synset('exsert.v.01'), Synset('extend.v.06'), Synset('offer.v.05'), Synset('stretch.v.02'), Synset('extend.v.09'), Synset('prolong.v.01'), Synset('unfold.v.03'), Synset('gallop.v.03'), Synset('extend.v.13'), Synset('strain.v.03'), Synset('extend.v.15'), Synset('carry.v.09'), Synset('extend.v.17')]\n",
      "the\n",
      "set()\n",
      "[]\n",
      "current\n",
      "{'current', 'stream'}\n",
      "[Synset('current.n.01'), Synset('current.n.02'), Synset('stream.n.02'), Synset('current.a.01')]\n",
      "CEQA\n",
      "set()\n",
      "[]\n",
      "exemption\n",
      "{'exemption'}\n",
      "[Synset('exemption.n.01'), Synset('exemption.n.02'), Synset('exemption.n.03')]\n",
      "deadline\n",
      "{'deadline'}\n",
      "[Synset('deadline.n.01')]\n",
      "for\n",
      "set()\n",
      "[]\n",
      "Bachelor_of_Science antimony   strain stretch gallop unfold run cover offer carry prolong exsert extend widen  current stream  exemption deadline \n"
     ]
    }
   ],
   "source": [
    "utterance = 'SB 1008 would extend the current CEQA exemption deadline for'\n",
    "for word in utterance.split():\n",
    "    print (word)\n",
    "    syn = wordnet.synsets(word)\n",
    "    lemmas = set([s.lemmas()[0].name() for s in syn])\n",
    "    print (lemmas)\n",
    "    print (syn)\n",
    "    utterance = utterance.replace(word, ' '.join(lemmas))\n",
    "print (utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'impart', 'carry', 'stock', 'transport', 'post', 'have_a_bun_in_the_oven', 'behave', 'hold', 'dribble'}\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets('carry')\n",
    "lemmas = set([s.lemmas()[0].name() for s in syn])\n",
    "print (lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
