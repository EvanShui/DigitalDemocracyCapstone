{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/brucerowan/Documents/capstone/DigitalDemocracyCapstone/\"\n",
    "target_col = 'transition_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_output_filename = data_dir  + \"training_utterances_n_range_collapsed.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset evenly based on labels\n",
    "def split_test_train(total, stratify_col):\n",
    "    transition_rows = total[total[stratify_col] != 0]\n",
    "    non_transition_rows = total[total[stratify_col] == 0]\n",
    "    \n",
    "    # first split transitions into training/testing\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(transition_rows, \n",
    "                                                    transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # assert there are only transition labels in this dataframe\n",
    "    assert len(X_train1[X_train1[target_col] == 0]) == 0\n",
    "    assert len(X_test1[X_test1[target_col] == 0]) == 0\n",
    "    \n",
    "    train_len = len(X_train1) # number of non-transitions to add to training set\n",
    "    test_len = len(X_test1) # number of non-transitions to add to testing set\n",
    "    \n",
    "    \n",
    "    # next split non-transitions into training/testing\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(non_transition_rows, \n",
    "                                                    non_transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # pick train_len random rows from non-transition training set\n",
    "    ###change n = train_len\n",
    "    print(train_len)\n",
    "    X_train2 = X_train2.sample(n = train_len*4, axis=0)\n",
    "    \n",
    "    # pick test_len random rows from non_transitions testing set\n",
    "    X_test2 = X_test2.sample(n = test_len, axis=0)\n",
    "    \n",
    "    # assert there are no transition utterances in non-transition training and testing set\n",
    "    assert len(X_train2[X_train2[target_col] != 0]) == 0\n",
    "    assert len(X_test2[X_test2[target_col] != 0]) == 0\n",
    "    \n",
    "    # final result, concat the dataframe\n",
    "    X_train_final = pd.concat([X_train1, X_train2])\n",
    "    X_test_final = pd.concat([X_test1, X_test2])\n",
    "    return X_train_final['text'], X_test_final['text'], X_train_final[target_col], X_test_final[target_col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(training_output_filename, sep = \"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_table(training_output_filename, sep=\"~\")[['text', target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'transition_value'], dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all 2's into 1's\n",
    "train.loc[train['transition_value'] > 0, 'transition_value'] = 1\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2044\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_test_train(train, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48865                                                    1 \n",
       "303181                                                   1 \n",
       "582147                                                 1 1 \n",
       "259517                                                   1 \n",
       "12024                                                    1 \n",
       "309185                                                   1 \n",
       "116326                                                 1 1 \n",
       "141389                                                   1 \n",
       "81597                                                    1 \n",
       "371396                                                   1 \n",
       "30038                                                  1 1 \n",
       "307931                                                   1 \n",
       "32113                                                1 1 1 \n",
       "345028                                                 1 1 \n",
       "602493                                                   1 \n",
       "643778                                                   1 \n",
       "42904                                                    1 \n",
       "52894                                                    1 \n",
       "73855                                                    1 \n",
       "397176                                                 1 1 \n",
       "615001                                                   1 \n",
       "398592                                                   1 \n",
       "586895                                                   1 \n",
       "645143                                                   1 \n",
       "89565                                                    1 \n",
       "438789                                                   1 \n",
       "436328                                                   1 \n",
       "373096                                                   1 \n",
       "134101                                                   1 \n",
       "37749                                                  1 1 \n",
       "                                ...                        \n",
       "85682                                            Thank you.\n",
       "406066    And I just, I'd like to applaud the author for...\n",
       "570088    I just want to echo that I've been impressed b...\n",
       "613812    appreciate your patience and appreciate the we...\n",
       "72809       Mid-july berryhill cannella daley owned by paul\n",
       "24738     two budget committee and forty two governmenta...\n",
       "31985     To add a few more votes fifteen I believe it's...\n",
       "418628    California's Knox-Keene Act requires health pl...\n",
       "63581     policies to address the demand side of human t...\n",
       "261334    the banks are not in a position to give them t...\n",
       "264148    Just so you know, currently the CPUC Passenger...\n",
       "596968    The Girl Scouts are the preeminent leadership ...\n",
       "491541    successful models to better serve children and...\n",
       "451852                                   Aye, Liu? Mendoza?\n",
       "253702                                         Maienschein?\n",
       "462926    there is no cost for our interstate motor carr...\n",
       "242595                                        Fair process.\n",
       "411135    There is no opposition to this bill, and I res...\n",
       "552653    could be intentional it could be argued in cou...\n",
       "122957                               Aye. Mitchell. >> Aye.\n",
       "2430                                 rise here to represent\n",
       "541303                         Any witnesses in opposition?\n",
       "348948    Syrus Devers, Best Best and Krieger, on behalf...\n",
       "149005                                             Jackson.\n",
       "108678                 All members vote who desire to vote.\n",
       "397376                Are there other similar tax holidays?\n",
       "406698                             Witnesses in opposition?\n",
       "236138    The AB 1653 will also define campus climate as...\n",
       "155658                                Aye. >> Aye, Morrell?\n",
       "104326    Members, AB 1346 would require the Office of E...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are 5226 transition phrases and 5226*6 = 31356 non transition phrases\n",
    "# 36582 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_rows = train[train[target_col] != 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert training and testing splits are the correct dimensions\n",
    "### After splitting, training and testing sets should each have 50% transitions and 50% non-transitions\n",
    "### training dimensions should be 2 * 70% of the number of transitions in the data set\n",
    "### testing dimensions should be 2 * 30% of the number of transitions in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(x_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-5cfd3ec863a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_rows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(x_train) == int(len(transition_rows) * 0.7) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(x_test) == (len(transition_rows) * 2) - (int(len(transition_rows) * 0.7) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-5ef45d58da1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(y_train[y_train == 0]) == len(y_train[y_train != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(y_test[y_test == 0]) == len(y_test[y_test != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize utterances with bag of words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(np.hstack((x_train, x_test)))\n",
    "X_train_counts = count_vect.transform(x_train)\n",
    "X_test_counts = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_train_counts.shape[1] == X_test_counts.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass vectorized utterances into a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output accuracy on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_test_counts.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4908779931584949"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_counts, y_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10220, 44)\n"
     ]
    }
   ],
   "source": [
    "#so all utterences are same length\n",
    "padded = pad_sequences(sequences, maxlen = 44)\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = to_categorical(y_train)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 150, input_length=44))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(150, dropout=0.2, recurrent_dropout=0.5))\n",
    "model.add(Dense(25,activation = 'sigmoid'))\n",
    "model.add(Dense(2, activation='sigmoid')) #fully connected layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class weights \n",
    "class_weight = {\n",
    "    0 : 1.,\n",
    "    1: 4.,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  640/10220 [>.............................] - ETA: 1:08 - loss: 0.9490 - acc: 0.6992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-e393ef88cb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(padded, pred, epochs = 1,class_weight = class_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 44)\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(x_test)\n",
    "sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(sequences, maxlen = 44)\n",
    "print(test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_padded)\n",
    "predictions = np.argmax(predictions, axis =1)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86031927023945265"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423002      1 \n",
      "379313      1 \n",
      "457374      1 \n",
      "34923       1 \n",
      "567062      1 \n",
      "560620      1 \n",
      "158522      1 \n",
      "451998      1 \n",
      "560860      1 \n",
      "345489      1 \n",
      "288509      1 \n",
      "65833       1 \n",
      "283041      1 \n",
      "573038      1 \n",
      "22864       1 \n",
      "121702    1 1 \n",
      "387985    1 1 \n",
      "148984      1 \n",
      "190710      1 \n",
      "68107       1 \n",
      "359052      1 \n",
      "261872      1 \n",
      "359109      1 \n",
      "68198       1 \n",
      "68518       1 \n",
      "272029      1 \n",
      "98234     1 1 \n",
      "40679     1 1 \n",
      "44579       1 \n",
      "621290      1 \n",
      "          ... \n",
      "120465      1 \n",
      "200630      1 \n",
      "394745      1 \n",
      "646888      1 \n",
      "562062      1 \n",
      "9267        1 \n",
      "119185      1 \n",
      "592359      1 \n",
      "590931      1 \n",
      "439758      1 \n",
      "147533      1 \n",
      "619218    1 1 \n",
      "33183       1 \n",
      "568309      1 \n",
      "372555      1 \n",
      "97352       1 \n",
      "636649      1 \n",
      "371350      1 \n",
      "287380      1 \n",
      "304555      1 \n",
      "286125      1 \n",
      "493307    1 1 \n",
      "356875      1 \n",
      "50609       1 \n",
      "291410      1 \n",
      "400873      1 \n",
      "435686      1 \n",
      "279151      1 \n",
      "339481      1 \n",
      "67150       1 \n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x_test.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 1 \n",
      "0 1 1 1 \n",
      "0 1 1 1 \n",
      "1 0 Huff?\n",
      "1 0 ...honor galena ...patricia\n",
      "1 0 Understand ...\n",
      "1 0 Hueso.\n",
      "1 0 Leyva?\n",
      "1 0 Ayes 3, nos two.\n",
      "1 0 Mendoza.\n",
      "1 0 Dahle.\n",
      "1 0 Aye.\n",
      "1 0 No file.\n",
      "1 0 Gaines?\n",
      "1 0 Ayes 70, noes 0.\n",
      "1 0 Paul? >> Present.\n",
      "1 0 Aye.\n",
      "1 0 Nielsen?\n",
      "1 0 Mitchell.\n",
      "1 0 Hall present.\n",
      "1 0 Gipson?\n",
      "1 0 Senator Pavley.\n",
      "1 0 bar dues ...\n",
      "1 0 Salas.\n",
      "1 0 Mm-hm.\n",
      "1 0 Morning.\n",
      "1 0 Dahle?\n",
      "1 0 Stone?\n",
      "1 0 Lu? >> No.\n",
      "1 0 [UNKNOWN]?\n",
      "1 0 Cooley?\n",
      "1 0 Not voting.\n",
      "1 0 I'm sorry.\n",
      "1 0 Aye.\n",
      "1 0 Enough, next.\n",
      "1 0 Aye.\n",
      "1 0 Stone, Vidak.\n",
      "1 0 Aye.\n",
      "1 0 Leyva?\n",
      "1 0 Aye.\n",
      "1 0 Not voting.\n",
      "1 0 Galgiani...hancock\n",
      "1 0 [INAUDIBLE]\n",
      "1 0 Jackson.\n",
      "1 0 Galgiani?\n",
      "1 0 Aye.\n",
      "1 0 Aye.\n",
      "1 0 [INAUDIBLE]\n",
      "1 0 Aye.\n",
      "1 0 Gomez?\n",
      "1 0 Aye.\n",
      "1 0 Aye.\n",
      "1 0 Aye.\n",
      "1 0 Additional testimony.\n",
      "1 0 No.\n",
      "1 0 Calderon.\n",
      "1 0 Hall?\n",
      "1 0 Morrell?\n",
      "1 0 Senators Pavley.\n",
      "1 0 Aye.\n",
      "1 0 No, windows.\n",
      "1 0 Aye\n",
      "1 0 No.\n",
      "1 0 Ridley-Thomas.\n",
      "1 0 Hernandez?\n",
      "1 0 Aye.\n",
      "1 0 Liu?\n",
      "1 0 Senator Leno\n",
      "1 0 Senator Wolk.\n",
      "1 0 Mr. Gordon.\n",
      "1 0 Jackson?\n",
      "1 0 Pretty lonely time.\n",
      "1 0 Passed temporarily.\n",
      "1 0 He said yes.\n",
      "1 0 Frazier?\n",
      "1 0 Aye.\n",
      "1 0 Mendoza, Runner.\n",
      "1 0 Christina Garcia.\n",
      "1 0 Runner.\n",
      "1 0 Obernolte?\n",
      "1 0 Aye.\n",
      "1 0 Hancock, Huff, Leyva.\n",
      "1 0 Allen.\n",
      "1 0 No, jackson.\n",
      "1 0 Mitchell?\n",
      "1 0 Ayes 76, nos zero.\n",
      "1 0 Measure passes.\n",
      "1 0 Galgiani?\n",
      "1 0 Jackson.\n",
      "1 0 Pan.\n",
      "1 0 Roll call.\n",
      "1 0 No,...\n",
      "1 0 Campos?\n",
      "1 0 Aye.\n",
      "1 0 Kim?\n",
      "1 0 Ayes 63, no's 0.\n",
      "1 0 Allen? Anderson?\n",
      "1 0 No.\n",
      "1 0 No, Nielsen?\n",
      "1 0 Aye.\n",
      "1 0 Yes.\n",
      "1 0 Aye.\n",
      "1 0 McGuire?\n",
      "1 0 Here.\n",
      "1 0 Aye.\n",
      "1 0 Any comments, concerns?\n",
      "1 0 Aye.\n",
      "1 0 Aye.\n",
      "1 0 [INAUDIBLE]\n",
      "1 0 Allen?\n",
      "1 0 Aye.\n",
      "1 0 Wolk?\n",
      "1 0 Jim Green, hunter conservationist.\n",
      "1 0 Aye.\n",
      "1 0 Mr. Gordon.\n",
      "1 0 Chau?\n",
      "1 0 Mr. Chairman.\n",
      "1 0 Senator Morrell.\n",
      "1 0 Aye.\n",
      "1 0 Nazarian?\n",
      "1 0 Monning?\n",
      "1 0 Aye.\n",
      "1 0 Good thing.\n",
      "1 0 Aye.\n",
      "1 0 Senator Bates.\n",
      "1 0 Aye.\n",
      "1 0 Senator Hill.\n"
     ]
    }
   ],
   "source": [
    "wrong = 0\n",
    "missed_transition = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] != y_test.iloc[i]:\n",
    "        wrong= wrong+1\n",
    "        print(predictions[i],y_test.iloc[i],x_test.iloc[i])\n",
    "        if predictions[i] == 0:\n",
    "            missed_transition = missed_transition +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n",
      "877\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(wrong)\n",
    "print(missed_transition)\n",
    "print(missed_transition/wrong)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "3 epochs seems to be the sweet spot\n",
    "\n",
    "(using 6 times more non transitions)\n",
    "\n",
    "model 1: 1 epochs, adam optimzer, class weights(0:1,1:6)\n",
    "accuracy score: 58.06%, (61% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 4 epochs, adam optimzer, class weights(0:1,1:6)\n",
    "accuracy score: 53.46%, (72% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 10 epochs, adam optimzer, class weights (0:1,1:6)\n",
    "accuracy score: 53.31%, (61% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 15 epochs, adam optimzer, class weights (0:1,1:6)\n",
    "accuracy score: 53.15%, (71% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 20 epochs, adam optimzer, class weights (0:1,1:6)\n",
    "accuracy score: 51.36%, (69% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 25 epochs, adam optimzer, class weights (0:1,1:6)\n",
    "accuracy score: 52.83%, (67% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 30 epochs, adam optimzer, class weights (0:1,1:6)\n",
    "accuracy score: 51.65%, (73% guessed 0 when correct was 1)\n",
    "\n",
    "model 1: 1 epochs, rmsprop, class weights (0:1,1:6)\n",
    "accuracy score: 45.5%, (74% guessed 0 when correct was 1)\n",
    "\n",
    "###model 2 \n",
    "\n",
    "1 epoch, adam\n",
    "accuracy score: 51.4%, (67.8% guessed 0 when correct was 1)\n",
    "\n",
    "4 epochs, adam\n",
    "accuracy score: 52.0%, (71.8% guessed 0 when correct was 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### model1 \n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 150, input_length=44))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(150, dropout=0.2, recurrent_dropout=0.5))\n",
    "model.add(Dense(2, activation='sigmoid')) #fully connected layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### model2 (remove conv layer and pooling layer)\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 150, input_length=44))\n",
    "\n",
    "model.add(LSTM(150, dropout=0.2, recurrent_dropout=0.5))\n",
    "model.add(Dense(2, activation='sigmoid')) #fully connected layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## model 3(model 1 with another dense layer) 59% acc on n_range data\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 150, input_length=44))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(150, dropout=0.2, recurrent_dropout=0.5))\n",
    "model.add(Dense(25,activation = 'sigmoid'))\n",
    "model.add(Dense(2, activation='sigmoid')) #fully connected layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
