{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/soniamannan/Documents/DATA401/capstone/digitaldemocracy_ds_capstone_2018/\"\n",
    "target_col = 'utterance_transition_values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_output_filename = data_dir + \"training/\" + \"training_utterances.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset evenly based on labels\n",
    "def split_test_train(total, stratify_col):\n",
    "    transition_rows = total[total[stratify_col] != 0]\n",
    "    non_transition_rows = total[total[stratify_col] == 0]\n",
    "    \n",
    "    # first split transitions into training/testing\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(transition_rows, \n",
    "                                                    transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # assert there are only transition labels in this dataframe\n",
    "    assert len(X_train1[X_train1[target_col] == 0]) == 0\n",
    "    assert len(X_test1[X_test1[target_col] == 0]) == 0\n",
    "    \n",
    "    train_len = len(X_train1) # number of non-transitions to add to training set\n",
    "    test_len = len(X_test1) # number of non-transitions to add to testing set\n",
    "    \n",
    "    \n",
    "    # next split non-transitions into training/testing\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(non_transition_rows, \n",
    "                                                    non_transition_rows[target_col], \n",
    "                                                    test_size=0.30, random_state=42)\n",
    "    \n",
    "    # pick train_len random rows from non-transition training set\n",
    "    X_train2 = X_train2.sample(n = train_len, axis=0)\n",
    "    \n",
    "    # pick test_len random rows from non_transitions testing set\n",
    "    X_test2 = X_test2.sample(n = test_len, axis=0)\n",
    "    \n",
    "    # assert there are no transition utterances in non-transition training and testing set\n",
    "    assert len(X_train2[X_train2[target_col] != 0]) == 0\n",
    "    assert len(X_test2[X_test2[target_col] != 0]) == 0\n",
    "    \n",
    "    # final result, concat the dataframe\n",
    "    X_train_final = pd.concat([X_train1, X_train2])\n",
    "    X_test_final = pd.concat([X_test1, X_test2])\n",
    "    \n",
    "    return X_train_final['text'], X_test_final['text'], X_train_final[target_col], X_test_final[target_col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table(training_output_filename, sep=\"~\")[['text', target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>utterance_transition_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We don't have a quorum yet I don't believe.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We don't have a quorum yet.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We'll ask the sergeants to please call the mem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that we can establish a quorum for this partic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the Assembly's 2nd Extraordinary Sessi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0        We don't have a quorum yet I don't believe.   \n",
       "1                        We don't have a quorum yet.   \n",
       "2  We'll ask the sergeants to please call the mem...   \n",
       "3  that we can establish a quorum for this partic...   \n",
       "4  This is the Assembly's 2nd Extraordinary Sessi...   \n",
       "\n",
       "   utterance_transition_values  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_test_train(train, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_rows = train[train[target_col] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert training and testing splits are the correct dimensions\n",
    "### After splitting, training and testing sets should each have 50% transitions and 50% non-transitions\n",
    "### training dimensions should be 2 * 70% of the number of transitions in the data set\n",
    "### testing dimensions should be 2 * 30% of the number of transitions in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(x_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_train) == int(len(transition_rows) * 0.7) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_test) == (len(transition_rows) * 2) - (int(len(transition_rows) * 0.7) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y_train[y_train == 0]) == len(y_train[y_train != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(y_test[y_test == 0]) == len(y_test[y_test != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize utterances with bag of words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(np.hstack((x_train, x_test)))\n",
    "X_train_counts = count_vect.transform(x_train)\n",
    "X_test_counts = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_counts.shape[1] == X_test_counts.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass vectorized utterances into a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output accuracy on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_test_counts.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74196428571428574"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_counts, y_test, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
